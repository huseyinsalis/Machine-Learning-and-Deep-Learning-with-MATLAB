{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 42s 695us/sample - loss: 0.1703 - accuracy: 0.9475 - val_loss: 0.0437 - val_accuracy: 0.9854\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 41s 685us/sample - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.0356 - val_accuracy: 0.9878\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 42s 692us/sample - loss: 0.0323 - accuracy: 0.9906 - val_loss: 0.0377 - val_accuracy: 0.9862\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 41s 690us/sample - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.0340 - val_accuracy: 0.9896\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 42s 692us/sample - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0278 - val_accuracy: 0.9918\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 42s 699us/sample - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0361 - val_accuracy: 0.9895\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 41s 691us/sample - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0257 - val_accuracy: 0.9924\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 41s 689us/sample - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0291 - val_accuracy: 0.9916\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 41s 688us/sample - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0277 - val_accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 42s 696us/sample - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0335 - val_accuracy: 0.9925\n",
      "10000/10000 [==============================] - 2s 189us/sample - loss: 0.0335 - accuracy: 0.9925\n",
      "Test loss: 0.0335174824580872\n",
      "Test accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.save(\"cov_f_minst.h5\")\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"589logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"cov_f_mnist_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "log_dir = get_run_logdir() \n",
    "\n",
    "tensorb = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch',profile_batch = 100000000)\n",
    "\n",
    "callbacks = [tensorb]\n",
    "\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    validation_data=(test_images, test_labels), \n",
    "                    epochs=10, batch_size=64,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(test_images, test_labels, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
